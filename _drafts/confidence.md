---
title: Confidence
layout: post
---

Confidence Intervals are an interesting thing.

brief history of CIs

So I think it would be interesting to do a comparison of the different explanations that are out there.

The things to avoid.

The things that you SHOULD say

The things that you SHOULD NOT say - and hilarious examples of what this would actually be like saying.

Hell, I think I should do this for everything.  Wouldn't that be cool?  A qualitative analysis of the difference in explanations of statistics - psychologists versus statisticians.  We could count the # of words used, and the common types of words used.  The words that are only used in one, and not the other.

Sidetracked.  Getting sidetracked.

Here is how Howell defines them.

this is taken directly from howell and is definitely plagiarism.

Regarding one-sample mean tests....
<ul>
	<li>Confidence intervals are a useful way to convey the meaning of an experimental result that goes beyond the simple hypothesis test.</li>
	<li>If we want to set limits that are likely to include µ given the data at hand, what we are really want is to ask how large, or small, the true value of µ could be without causing us to reject H0 if we ran a t test on the obtained sample mean</li>
	<li>Any estimate of µ between those upper and lower limits would lead us to retain the null hypothesis</li>
	<li>Once you have obtained your CI...
<ul>
	<li>The probability is 0.95 that intervals calculated as we have calculated the 95% interval above include the true mean ratio for our...experiment?</li>
</ul>
</li>
	<li>We can think of the parameter (µ) as a stake, and the experimenter, in computing confidence limits, as tossing rings at it.  95% of the time, a ring of specified width will encircle the parameter; 5% of the time, it will miss.  A confidence statement is a statement of the probability that the ring has been on target; it is not a statement of the probability that the target (parameter µ) landed in the ring.
<ul>
	<li>???i.e., We have accurately estimated µ; not that µ has falled within the estimates we made...?</li>
</ul>
</li>
</ul>
<strong>Two sample</strong>

We are setting confidence limits on the difference between µ1 and µ2.

H0 stipulates that µ1 - µ2 = 0.

As said earlier, a confidence limit gives us the highest, and lowest value under which we would reject H0.

This...doesn't really seem to apply here.

As I understand it, we are getting the <strong>distribution</strong> for the difference between µ1 and µ2.

H0 says that this distribution should have a mean/mode of 0.

H1 says that the distribution should NOT have a mean/mode of 0.  Heck, let's just aim to not have 0 in there.  That'll show them that this difference is <em>pretty unlikely</em>.

So, what we do is we put down some limits.  We lay down some stakes that encompass the 95% of the distribution and ask: <em>does zero occur here?  In this area...that is 95% of the data differences...</em>

<strong>What's so cool about Confidence Intervals?</strong>

They allow you to say - yes, these two populations ARE different from one another.

They also allow you to say: - how CERTAIN are we?  what's the range that 95% of the data falls in?

And what does the range allow you to say?  Well, if you have a mean of 7, but the possible range is within 1 and 13...then you have a wide variance.

But this could depend on the data.

We must always ask the question: <strong>but what does that <em>mean?</em></strong><em> </em>

It depends on the CONTEXT (reference post about context).

Your Confidence Limit could be from 0.1 to 0.5 - to which you would exclaim - hellz yeah!  I'm totally CERTAIN about my result.

But then, this could be measures of difference in lung functioning measured in litres.  And a 400ml difference is huge.

Remember - ask - <strong><em>but what does this</em> mean?</strong>  It usually relates to context, which is important.